from fugashi import Tagger
import unidic_lite
import os
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# MeCabè¨­å®š
os.environ["MECABRC"] = os.path.join(unidic_lite.DICDIR, "dicrc")
tagger = Tagger()

# ã²ã‚‰ãŒãªå¤‰æ›ï¼‹ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
def to_hiragana_tokens(text):
    kana_map = str.maketrans(
        "ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ãƒ˜ãƒ›ãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ¯ãƒ²ãƒ³ãƒ´ãƒ¼",
        "ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã¤ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚’ã‚“ã¶ãƒ¼"
    )
    tokens = []
    for m in tagger(text):
        raw = m.feature[7] if len(m.feature) > 7 and m.feature[7] not in (None, "*") else m.surface
        clean = str(raw).split("-")[0]
        hira = clean.translate(kana_map).lower()
        tokens.append(hira)
    return tokens

# ãƒˆãƒ¼ã‚¯ãƒ³ç…§åˆï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰
def token_match(input_text, target_text):
    input_tokens = to_hiragana_tokens(input_text)
    target_tokens = to_hiragana_tokens(target_text)
    return any(tok in target_tokens for tok in input_tokens)

# Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
def get_sheet_data(sheet_name):
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_name('food-checker-473911-f196582d590.json', scope)
    client = gspread.authorize(creds)
    spreadsheet = client.open("çŸ³å±±ã®è¦ç´„æƒ…å ±")
    worksheet = spreadsheet.worksheet(sheet_name)
    return worksheet.get_all_values()

# ç…§åˆé–¢æ•°ï¼ˆFlaskã‹ã‚‰å‘¼ã³å‡ºã™ï¼‰
def check_food(text):
    sheets = ["ä¸é£Ÿå“", "å¯é£Ÿå“"]
    normalized_input = text.strip()
    results = []

    for sheet_name in sheets:
        rows = get_sheet_data(sheet_name)
        for row in rows[3:]:  # 4è¡Œç›®ã‹ã‚‰ç…§åˆé–‹å§‹
            b_val = row[1] if len(row) > 1 else ""
            c_val = row[2] if len(row) > 2 else ""

            if not b_val:
                continue

            if normalized_input.lower() == b_val.strip().lower():
                msg = f"âœ… {sheet_name}ã«å®Œå…¨ä¸€è‡´ã—ã¾ã—ãŸï¼š{b_val}"
                if c_val:
                    msg += f"å‚™è€ƒï¼š{c_val}"
                results.append(msg)
                return results

            if token_match(normalized_input, b_val):
                msg = f"ğŸ” {sheet_name}ã«éƒ¨åˆ†ä¸€è‡´ã—ã¾ã—ãŸï¼š{b_val}"
                if c_val:
                    msg += f"å‚™è€ƒï¼š{c_val}"
                results.append(msg)

    if not results:
        results.append('âš ï¸ åˆ¤å®šä¸èƒ½ã§ã™ã€‚<a href="https://forms.gle/8YMNuueEZqaEKAox8" target="_blank">Googleãƒ•ã‚©ãƒ¼ãƒ </a>ã‚‚ã—ãã¯LINEã€Slackç­‰ã§é€£çµ¡ã—ã¦ãã ã•ã„ã€‚')

    return results
